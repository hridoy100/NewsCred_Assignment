{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exercise_2_Text Classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bPryVtgxj3Or",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efe68279-466b-4a4a-96a0-4be1c898c383"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['24', 'milkshakes', 'with', 'more', 'calories', 'than', 'an', 'entire', 'meal']\n",
            "['why', 'dividend-paying', 'aerospace', 'and', 'defense', 'stocks', 'should', 'be', 'bought', 'now', 'during', 'covid-19', 'pandemic']\n",
            "['difficulties', 'during', 'the', 'mighty', 'pandemic', 'covid-19']\n",
            "['this', 'is', 'how', 'many', 'people', 'are', 'retired', 'in', 'every', 'state']\n",
            "['the', '25', 'best', 'states', 'for', 'fishing']\n",
            "['labour', 'epidural', 'analgesia', 'not', 'associated', 'with', 'autism', 'spectrum', 'disorder']\n",
            "['these', 'very', 'famous', 'people', 'all', 'died', 'at', 'the', 'dinner', 'table']\n",
            "['chadox1', 'ncov-19', 'astrazeneca', 'covid-19', 'vaccine', 'not', 'effective', 'against', 'b.1.351', 'variant']\n",
            "['2', 'minute', 'medicine', 'rewind', 'march', '15', '2021']\n"
          ]
        }
      ],
      "source": [
        "from urllib.request import urlopen\n",
        "import json\n",
        "import collections\n",
        "import re\n",
        "import string\n",
        "import pandas as pd\n",
        "\n",
        "url = \"https://api.welcomesoftware.com/v2/feed/49e82ccda46544ff4e48a5fc3f04e343?format=json\"\n",
        "response = urlopen(url)\n",
        "  \n",
        "# storing the JSON response \n",
        "# from url in data\n",
        "data_json = json.loads(response.read())\n",
        "\n",
        "def remove_number(str):\n",
        "    str = re.sub(r'[0-9]+', '', str)\n",
        "    return str\n",
        "\n",
        "def remove_comma_semi_colon(str):\n",
        "    str = re.sub(r'[,:;\\()]', '', str)\n",
        "    return str\n",
        "\n",
        "def split_with_hyphen(str):\n",
        "    str = re.sub(r'-', ' ', str)\n",
        "    return str\n",
        "\n",
        "contents = dict()\n",
        "count = {}\n",
        "guid_map = {}\n",
        "for x in data_json[\"entries\"]:\n",
        "  str = x[\"content\"]\n",
        "  guid_map[str[\"guid\"]] = str\n",
        "  str[\"title\"] = remove_comma_semi_colon(str[\"title\"])\n",
        "  \n",
        "  words = str[\"title\"].split()\n",
        "  words = [word.lower() for word in words]\n",
        "  # print(words)\n",
        "  for word in words:\n",
        "    if word in count:\n",
        "      count[word] += 1\n",
        "    else:\n",
        "      count[word] = 1\n",
        "  contents[str[\"guid\"]]=words\n",
        "score = {}\n",
        "for key in contents:\n",
        "  sum=0\n",
        "  for word in contents[key]:\n",
        "    sum+=count[word]\n",
        "  score[key] = sum\n",
        "\n",
        "score = dict(sorted(score.items(), key=lambda kv: kv[1], reverse=True))\n",
        "\n",
        "dd = collections.defaultdict(list)\n",
        "for k,v in score.items():\n",
        "    dd[v].append(k)\n",
        "topScores = sorted(dd.items())\n",
        "df = pd.DataFrame(columns=['Guid','Title','Related Image Urls','Publish Date','Creation Date','Recurrence count sum of words'])\n",
        "\n",
        "for i in range(1, 4):\n",
        "  value = topScores[-i][0]\n",
        "  guids = topScores[-i][1]\n",
        "  for guid in guids:\n",
        "    content = guid_map[guid]\n",
        "    image_urls = []\n",
        "    for image in content[\"images\"]:\n",
        "      image_urls.append(image[\"url\"])\n",
        "    row = {'Guid': content[\"guid\"], 'Title': content[\"title\"], \n",
        "           'Related Image Urls': \",\".join(image_urls),\n",
        "           'Publish Date': content[\"published_at\"],\n",
        "           'Creation Date': content[\"created_at\"],\n",
        "           'Recurrence count sum of words': value}\n",
        "    df = df.append(row, ignore_index=True)\n",
        "\n",
        "df.to_csv('reccurrence.csv', index=False)"
      ]
    }
  ]
}